{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "### 1. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/X_train_res.csv')\n",
    "X_test = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/X_test.csv')\n",
    "X_val = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/X_val.csv')\n",
    "y_train_res = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/y_train_res.csv')\n",
    "y_test = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/y_test.csv')\n",
    "y_val = pd.read_csv('/Users/nandaniyadav/McGill MMA/Winter 2024/INSY 695/Group Project/customer_churn_2024/data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CatBoost Classifier\n",
    "catboost_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, loss_function='Logloss', verbose=200)\n",
    "\n",
    "# Train the model with resampled train and test data\n",
    "catboost_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# %%\n",
    "\n",
    "# predicting and evaluating model on validation set\n",
    "y_val_pred = catboost_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation Report: {val_report}')\n",
    "\n",
    "#confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_val, y_val_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test set\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)\n",
    "\n",
    "# confusion matrix on test set\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. using Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "model = CatBoostClassifier(verbose=0)  # Turn off verbose to suppress detailed output for each fit\n",
    "\n",
    "# Define the parameters grid to search\n",
    "param_grid = {\n",
    "    'iterations': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "final_model_cat_grid = grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# After fitting, you can get the best parameters and the best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_parameters}\")\n",
    "print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**param, verbose=0)\n",
    "    model.fit(X_train_res, y_train_res, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=0)\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print('Best parameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on validation set\n",
    "final_model = CatBoostClassifier(**best_params, verbose=0)\n",
    "final_model.fit(X_train_res, y_train_res, eval_set=[(X_val, y_val)], early_stopping_rounds=100, verbose=0)\n",
    "y_val_pred = final_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "#printing the accuracy and classification report\n",
    "print(f'Validation Accuracy: {val_accuracy}')   \n",
    "print(f'Validation Report: {val_report}')\n",
    "\n",
    "#prinitng confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "#printing the accuracy and classification report\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "#prinitng confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "viz = PrecisionRecallCurve(final_model, is_fitted=True)\n",
    "viz.fit(X_train_res, y_train_res)\n",
    "viz.score(X_val, y_val)\n",
    "viz.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
